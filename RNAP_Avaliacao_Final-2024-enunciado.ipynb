{"cells":[{"cell_type":"markdown","metadata":{"id":"K8CDQUj8yqpq"},"source":["## MBA em Ciência de Dados\n","# Redes Neurais e Aprendizado Profundo\n","\n","## <span style=\"color:darkred\">Avaliação Final - 2024 : Enuncaido</span>\n","\n","Moacir Antonelli Ponti\n","\n","CeMEAI - ICMC/USP São Carlos\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"F3wP5kcQVYj5"},"source":["Nessa avaliação será utilizado o dataset `imdb-reviews-pt-br.csv` que contém avaliações de filmes realizadas no site IMDB, com textos em português e em inglês. O alvo do dataset é a coluna `sentiment` que contém o sentimento relacionado à avaliação: positivo ou negativo.\n","\n","Vamos explorar um sentence embedding pré-treinado para multiplos idiomas, e avaliar redes neurais comparando-as com relação aos textos em inglês e português.\n","\n","As tarefas a realizar são as seguintes:\n","\n","Preparação:\n","1. **Instalar o pacote** `sentence_transformers` e **carregar o modelo** 'stsb-xlm-r-multilingual' para geração de sentence embeddings, conforme mostrado no código abaixo.\n","2. **Carregar a base de dados** e obter uma amostra de 12 mil linhas (use o método `sample` do dataframe pandas).\n","3. **Gerar os embeddings** usando o método encode, para os textos em português e em inglês. Ver https://www.sbert.net/examples/applications/computing-embeddings/README.html para mais detalhes. OBS: pode demorar um pouco\n","4. **Separar dados** 75% para treinamento, 25% para teste usando `train_test_split`, sendo a mesma partição para ingles e portugues.\n","\n","Modelos:\n","1.  (1,0 pt) **Modelo A**: projete e treine uma rede neural profunda densa, utilizando como entrada os embeddings pré-treinados dos dados em **portugues** para análise de sentimento (classificação binária).<br>\n","    * A arquitetura deve ter portanto as seguintes camadas:\n","        * entrada\n","        * normalização em batch\n","        * densa 768 neurônios, relu\n","        * densa 512 neurônios, relu\n","        * densa 256 neurônios, ativação linear\n","        * normalização em batch\n","        * ativação relu\n","        * dropout 0.375\n","        * densa 1 neurônio, sigmoide\n","    * Utilizar Adam com taxa de aprendizado inicial de 0.0007 e com decaimento em todas as épocas exponencial a -0.09\n","    * Treinar com perda entropia cruzada por 15 épocas com batch size 20\n","    * Compute como métricas, além da perda, a área sob a curva ROC (AUC ROC) e a Acurácia Binária (ver https://www.tensorflow.org/api_docs/python/tf/keras/metrics)<br><br>\n","\n","2.  (1,0 pt) **Modelo B**: projete e treine uma rede neural profunda densa, utilizando como entrada os *textos tokenizados* em **português** para análise de sentimento (classificação binária).<br>\n","    * A arquitetura deve ter portanto as seguintes camadas:\n","        * entrada\n","        * camada embedding com max_words=5000 e dimensão do embedding de tamanho 386\n","        * camada convolucional 1d com 64 neuronios de tamanho 2 e padding='same', ativação relu\n","        * camada LSTM 512 neurônios, sem especificar ativação (manter a default)\n","        * densa 256 neurônios, ativação linear\n","        * normalização em batch\n","        * ativação relu\n","        * dropout 0.375\n","        * densa 1 neurônio, sigmoide\n","    * Utilizar os mesmos hiper-parâmetros de otimização, treinamento e métricas do modelo anterior<br><br>\n","\n","\n","3. (2,0 pt) **Avalie as rede neurais de classificação** (Modelos A e B):\n","    * Exiba o gráfico das métricas ROC AUC e Accuracy calculadas no treinamento ao longo das épocas para o modelos A e B\n","    * Calcule e exiba as métricas no conjunto de teste usando o cada modelo</br>\n","    3.1 (2,0 pt) **Conclua** sobre os resultados obtidos nos seus experimentos, conforme descrito abaixo no notebook.</br></br>\n","\n","4. (3,0 pt) **Fine-tuning** dos Modelo B com os dados em inglês, treinando por 15 épocas e batch_size=20, com Adam e taxa de aprendizado 0.00001 (sem decaimento):\n","    1. Modelo Fine Tuning versão 1: realize ajuste fino, congelando a camada de embeddings,\n","    2. Modelo Fine Tuning versão 2: realize ajuste fino, congelando a camada convolucional e a camada LSTM.\n","        \n","    * exibir a função de custo ao longo das épocas de treinamento para cada modelo,\n","    * calcular e exibir métricas dos modelos após fine-tuning usando o conjunto de teste em ingles (textos tokenizados)</br>\n","    4.1 (1,0 pt) **Conclua** sobre os resultados obtidos nos seus experimentos, conforme descrito abaixo no notebook.</br></br>\n","\n","5. **Bônus:** (+1 ponto extra)\n","    * *Análise visual das características*: visualize scatterplots com os 2 dimensões obtidos com o método tSNE as classes dos exemplos atribuídas com cores ou marcadores diferentes:\n","        1. scatterplot com projeção tSNE do conjunto de teste referente ao embedding pré-treinado em português,\n","        1. scatterplot com projeção tSNE da última camada densa de 256 dimensões extraído do conjunto de teste tokenizado em português referente ao *Modelo B*,\n","        1. scatterplot com projeção tSNE da última camada densa de 256 dimensões extraído do conjunto de teste em inglês (tokens) referente ao *Modelo B* após ajuste fino versão 2.\n","    * Escreva comentários com suas conclusões sobre a análise visual."]},{"cell_type":"markdown","metadata":{"id":"zsiVO6PeFer4"},"source":["## Preparação\n","\n","### 1. Carregar bibliotecas e modelo pré-treinado SentenceTransformer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UOJzPpWiVYj7","scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731683881654,"user_tz":180,"elapsed":8737,"user":{"displayName":"Moacir Antonelli Ponti","userId":"09722981635546271521"}},"outputId":"3115eebb-88da-48e6-b72c-203375c4c11f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  from tqdm.autonotebook import tqdm, trange\n"]}],"source":["import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","from numpy.random import seed\n","\n","from tensorflow.random import set_seed\n","import tensorflow.keras as keras\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","\n","from sklearn.model_selection import train_test_split\n","\n","from sentence_transformers import SentenceTransformer"]},{"cell_type":"markdown","source":["#### Verifique a versão do Tensorflow, recomendamos a 2.17.\n","OBS: o código pode ter problemas com a versão 2.18"],"metadata":{"id":"n9DdQn1wK9_S"}},{"cell_type":"code","source":["print(tf.__version__)"],"metadata":{"id":"NneTTayuQNqZ","executionInfo":{"status":"ok","timestamp":1731683934427,"user_tz":180,"elapsed":453,"user":{"displayName":"Moacir Antonelli Ponti","userId":"09722981635546271521"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1fd78e43-4c2a-4e7d-ddfd-dcb678b41066"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.17.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6590,"status":"ok","timestamp":1731683942613,"user":{"displayName":"Moacir Antonelli Ponti","userId":"09722981635546271521"},"user_tz":180},"id":"5ZFOaL2AFer7","outputId":"afa3dd84-b18f-45fc-d51a-e3f0fa4a70d1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["# baixar modelo codificador de setenças\n","model = SentenceTransformer('stsb-xlm-r-multilingual')"]},{"cell_type":"markdown","metadata":{"id":"7LbiwiojFer7"},"source":["### 2. Carregar base de dados e obter amostra"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10563,"status":"ok","timestamp":1731683953173,"user":{"displayName":"Moacir Antonelli Ponti","userId":"09722981635546271521"},"user_tz":180},"id":"or0t4PXkVYj_","outputId":"8ea057cf-faad-484c-fbf8-94151e3a2a74","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1ltAAPcaPD1epgs-F9i-nhaF350DPPrGK\n","From (redirected): https://drive.google.com/uc?id=1ltAAPcaPD1epgs-F9i-nhaF350DPPrGK&confirm=t&uuid=434b70d8-ac82-44c9-a573-5e79d12a1727\n","To: /content/imdb-reviews-pt-br.csv\n","100% 127M/127M [00:02<00:00, 48.4MB/s]\n"]}],"source":["!gdown 1ltAAPcaPD1epgs-F9i-nhaF350DPPrGK\n","\n","# ler base de dados\n","df_orig = pd.read_csv(\"imdb-reviews-pt-br.csv\", delimiter=',', engine='python')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":198},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1731683953176,"user":{"displayName":"Moacir Antonelli Ponti","userId":"09722981635546271521"},"user_tz":180},"id":"C_U247PSFer8","outputId":"bc4d5279-5ee3-4e36-85f0-688fc0637381"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["sentiment\n","pos    6018\n","neg    5982\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>sentiment</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>pos</th>\n","      <td>6018</td>\n","    </tr>\n","    <tr>\n","      <th>neg</th>\n","      <td>5982</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":6}],"source":["# obter amostra\n","df = df_orig.sample(12000).reset_index(drop=True)\n","df.sentiment.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"0F3SpjqQVYkA"},"source":["### 3. Separar dados em treinamento e teste e preparar rótulos\n","\n","Iremos também verificar o tamanho das strings em cada instancia, para considerar apenas um número de caracteres proporcional ao percentil 80."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1731683953178,"user":{"displayName":"Moacir Antonelli Ponti","userId":"09722981635546271521"},"user_tz":180},"id":"hEkwrMr2Fer-","outputId":"04ccc5b2-f9d1-4c5f-f67f-731c20e3daa0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":7}],"source":["# rotulos\n","y = np.array((df.sentiment=='pos').astype(int))\n","\n","X_train_txt_en, X_test_txt_en, y_train_en, y_test_en= train_test_split(df.text_en.values, y, test_size=0.25, random_state=51)\n","X_train_txt_pt, X_test_txt_pt, y_train_pt, y_test_pt= train_test_split(df.text_pt.values, y, test_size=0.25, random_state=51)\n","\n","sum(y_train_en!=y_train_pt)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1731683953178,"user":{"displayName":"Moacir Antonelli Ponti","userId":"09722981635546271521"},"user_tz":180},"id":"p3EI5kKN4FOu","outputId":"4a2623bb-0255-4b34-8889-929bb4961da9"},"outputs":[{"output_type":"stream","name":"stdout","text":["percentil 80.0: 312.0\n","percentil 95.0: 538.0\n","Maximo: 936\n"]}],"source":["# tamanhos das strings - usaremos o percentil 80 como tamanho da entrada máximo\n","num_words = df.text_pt.apply(lambda x: len(str(x).split()))\n","max_length = num_words.max()\n","percentile_80 = num_words.quantile(0.80)\n","percentile_95 = num_words.quantile(0.95)\n","\n","print(f\"percentil 80.0: {percentile_80}\")\n","print(f\"percentil 95.0: {percentile_95}\")\n","print(f\"Maximo: {max_length}\")"]},{"cell_type":"markdown","metadata":{"id":"S68Sms9jFer9"},"source":["### 4. Geração dos embeddings\n","\n","Utilizar o encoder carregado para obter os embeddings para treinamento e teste em Português e Inglês, separadamente.\n","\n","Exemplo de uso: `model.encode(texto, batch_size=16, show_progress_bar=True)`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qQnFf1IGFer9"},"outputs":[],"source":["X_train_en = model.encode(X_train_txt_en, batch_size=16, show_progress_bar=True)\n","# ..."]},{"cell_type":"markdown","metadata":{"id":"kaAMk9LR1aJS"},"source":["5. Tokenização do texto\n","\n","Definiremos um número máximo de palavras e um tamanho máximo de sequência com base nos dados em Português, conforme abaixo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SGEKCXmE1Skp"},"outputs":[],"source":["max_words = 5000  # Numero maximo de palavras\n","max_sequence_length = int(percentile_80)  # Tamanho maximo da sequencia igual ao percentil 80\n","\n","tokenizer = Tokenizer(num_words=max_words)\n","tokenizer.fit_on_texts(X_train_txt_pt)\n","\n","sequences_train = tokenizer.texts_to_sequences(X_train_txt_pt)\n","sequences_test = tokenizer.texts_to_sequences(X_test_txt_pt)\n","\n","# realizar padding para igualar sentencas\n","X_train_tok_pt = pad_sequences(sequences_train, maxlen=max_sequence_length)\n","X_test_tok_pt = pad_sequences(sequences_test, maxlen=max_sequence_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PneKQJQYC0uR"},"outputs":[],"source":["## realizar o mesmo procedimento para os textos em ingles\n","# use os mesmos parametros de maximo de palavras e sequencia"]},{"cell_type":"markdown","metadata":{"id":"bnzzkgSjVYkD"},"source":["---\n","\n","## Tarefas\n","\n","Definimos os modelos e iniciamos as tarefas. O código abaixo é uma referência para auxiliar na resolução, complete/altere conforme necessário."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4d4QsxYFer_"},"outputs":[],"source":["# DICA: use keras.layers.CAMADA para montar as arquiteturas\n","\n","# definir modelo A\n","def model_A(input_dim):\n","    input_data = keras.layers.Input(shape=(input_dim,))\n","    # ...\n","    output = keras.layers.Dense(1, activation='sigmoid')(x)\n","    dnn = keras.models.Model(input_data, output)\n","    return dnn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IVTJGVwa1fyY"},"outputs":[],"source":["# definir modelo B\n","def model_B(input_dim, max_words, embedding_dim=386, code_dim=256):\n","    input_layer = keras.layers.Input(shape=(input_dim,))\n","    embedding_layer = keras.layers.Embedding(max_words, embedding_dim, name='embedding')(input_layer)\n","    # ...\n","    output_layer = keras.layers.Dense(1, activation='sigmoid')(dropout_layer)\n","    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kwcMyVhMFer_"},"outputs":[],"source":["epochs = 15\n","batch_size = 20\n","lrate = 0.0007"]},{"cell_type":"markdown","metadata":{"id":"C93QhIDLFesA"},"source":["---\n","\n","### 1. (1,0 pt) Modelo A: classificador de sentimento em *portugues* usando embedding pré-treinado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7CSkZBFZVYkD"},"outputs":[],"source":["seed(1)\n","set_seed(2)\n","\n","def scheduler(epoch, lr):\n","    return float(lr * tf.math.exp(-0.09))\n","\n","callbacklr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","\n","# instanciar, compilar e treinar modelo A"]},{"cell_type":"markdown","metadata":{"id":"T3Pk0IvUVYkI"},"source":["---\n","\n","### 2. (1,0 pt) Modelo B: classificador de sentimento em *português* usando tokenizador e rede CNN+LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wPq9MVqyVYkJ","scrolled":true},"outputs":[],"source":["seed(1)\n","set_seed(2)\n","\n","# instanciar, compilar e treinar modelo B"]},{"cell_type":"markdown","metadata":{"id":"odoVvi5OVYkL"},"source":["---\n","\n","### 3. (2,0 pt) Avaliação dos modelos: métricas durante treinamento e avaliação das métricas no conjunto de teste de ambos os modelos"]},{"cell_type":"code","source":["## plot métricas durante treinamento dos modelos A e B"],"metadata":{"id":"Jqqvk1G1n0ev"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bltDvl7TFesC"},"outputs":[],"source":["## avaliacao no conjunto de teste dos modelos A e B treinados\n","# exibir os valores obtidos"]},{"cell_type":"markdown","source":["### 3.1 (2,0 pt) Escreva conclusões sobre a comparação entre os modelos A e B em termos:\n","- das métricas computadas ao longo do treinamento\n","- conclua sobre os resultados da generalização dos modelos e relacione esse resultado com a arquitetura de cada modelo (camadas utilizadas e número de parâmetros).\n","\n","Escreva apenas um parágrafo para cada um dos items acima. As conclusões devem fazer sentido com relação aos resultados obtidos no seu notebook."],"metadata":{"id":"mRMkUu-MaMRg"}},{"cell_type":"markdown","source":["< suas conclusões aqui >\n","- **Métricas de treinamento**:\n","- **Generalização e arquitetura**:"],"metadata":{"id":"zXT6B2A3cV4V"}},{"cell_type":"markdown","metadata":{"id":"dGqJ2dCFVYkM","scrolled":false},"source":["---\n","\n","### 4. (3,0 pt) Fine-tuning do Modelo B usando os dados em **ingles**\n","\n","O modelo foi treinado com dados em português e agora queremos realizar transferência de aprendizado, realizando ajuste fino dos parâmetros para que possa classificar texto em inglês.\n","\n","Serão feitos dois experimentos, ambos a partir dos pesos do modelo B, usando os tokens extraídos dos textos em ingles:\n","\n","1. Modelo B FT v1: congele a camada de embedding (ou seja setando essa camada como `trainable=False`), e permita que todas as demais possam se adaptar.\n","2. Modelo B FT v2: congele apenas a camada convolucional e a camada LSTM, e permita que todas as demais (inclusive a camada de embedding, anterior a essas) possam se adaptar.\n","\n","Após o treinamento compare ambos modelos exibindo:\n","- um gráfico com a loss ao longo do treinamento\n","- um gráfico com as métricas obtidas ao longo do treinamento\n","- as métricas (numéricas) obtidas no conjunto de teste"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dHJbCRsWD826"},"outputs":[],"source":["## Experimentos de Fine-tuning do Modelo B"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lLy290LZCiFG"},"outputs":[],"source":["# Cria novo modelo copiando a arquitetura e pesos anteriores\n","# ajusta camadas a serem treinadas ou congeladas\n","# realizar finetuning com learning rate fixo = 0.0001"]},{"cell_type":"code","source":["# visualiza loss de treinamento dos modelos"],"metadata":{"id":"0DbB7WLjUtVf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualiza métricas de treinamento dos modelos"],"metadata":{"id":"jZ8NVWcKV-KY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GZXh5N9zCsn4"},"outputs":[],"source":["# avaliacao e comparacao com dados de teste"]},{"cell_type":"markdown","source":["#### 5.1 (1,0 pt) Conclusões sobre o Fine-tuning realizado\n","\n","Conclua sobre o fine-tuning realizado, comparando os dois modelos abordando:\n","- a loss e métricas computadas ao longo do treinamento para cada modelo\n","- as métricas obtidas com os dados de teste\n","- compare os modelos em termos de sua capacidade de generalização, indicando as razões de terem generalizado melhor ou pior.\n","\n","As conclusões devem fazer sentido com relação aos resultados obtidos no seu notebook. Escreva um ou dois parágrafos com suas conclusões.\n","\n","_< suas conclusões >_"],"metadata":{"id":"ti99EwmBY8tc"}},{"cell_type":"markdown","metadata":{"id":"ZkbF9yq8VYkN"},"source":["---\n","## Bônus (+1pt)\n","\n","### Análise visual e conclusões\n","\n","A partir dos espaços de características dos dados de teste usando tSNE em duas dimensões:\n","\n","a. Espaço embedding original dos dados de teste em portugues,<br>\n","b. Espaço embedding Modelo B dos dados de teste em português,<br>\n","c. Espaço embedding Modelo B ajustado para inglês (segunda versão do finetuning) dos dados de teste em ingles.\n","\n","Tarefas:\n","1. Plote os espaços projetados em 2D pelo TNSE usando os parametros definidos no exemplo abaixo. Utilize cores e/ou formatos de pontos no gráfico de forma a diferenciar os pontos de cada classe.\n","\n","2. Escreva um parágrafo com conclusões sobre essa análise visual do espaço embedding/características aprendidas. As conclusões tem que fazer sentido com os plots exibidos.\n","\n","_<suas conclusões>_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qsGtSQLVVYkN"},"outputs":[],"source":["from sklearn.manifold import TSNE\n","\n","#parametros TSNE\n","#TSNE(n_components=2, learning_rate='auto', init='pca', perplexity=6)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9OV4ec6GVYkQ"},"outputs":[],"source":["# plot dos espaços em 2D"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":0}